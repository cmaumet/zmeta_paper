%% This is file `elsarticle-template-1-num.tex',
%%
%% Copyright 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%%
%% $Id: elsarticle-template-1-num.tex 149 2009-10-08 05:01:15Z rishi $
%% $URL: http://lenova.river-valley.com/svn/elsbst/trunk/elsarticle-template-1-num.tex $
%%

%% Use the option review to obtain double line spacing
\documentclass[preprint]{elsarticle}
\usepackage[cm]{fullpage}

\usepackage{hyperref}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% The graphicx package provides the includegraphics command.
\usepackage{graphicx}
%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}


\usepackage{amsopn} % DeclareMathOperator
\usepackage{amsmath} % bmatrix
\usepackage{bm}

\DeclareMathOperator{\Var}{Var}
\newcommand{\effectvector}{\hat\beta}
\newcommand{\effect}[1][i]{\effectvector_{#1}}
\newcommand{\effectunits}[1][i]{\effect{#1}^*}
\newcommand{\vareffect}[1][i]{s^2_{#1}}
\newcommand{\vareffectunits}[1][i]{s^{2*}_{#1}}
\newcommand{\zeffect}[1][\studyidx]{Z_{#1}}
\newcommand{\peffect}[1][\studyidx]{P_{#1}}
\newcommand{\nStudies}{k}
\newcommand{\studyidx}{i}
\newcommand{\varCombined}{\sigma^2_{C}}
\newcommand{\estvarCombined}{\hat\sigma^2_{C}}

\newcommand{\metaanalyticeffect}{\gamma}

\newcommand{\varBetween}{\tau^2}
\newcommand{\estvarBetween}{\hat\tau^2}
\newcommand{\varWithinCommon}{\sigma^2}
\newcommand{\sampleSize}[1][i]{n_{#1}}
\newcommand{\varWithin}[1][i]{\sigma^2_{#1}}
\newcommand{\varWithinCon}[1][i]{\sigma^2_{#1} / \sampleSize[#1]}
\newcommand{\varWithinConInv}[1][i]{\sampleSize[#1] / \sigma^2_{#1}}
\newcommand{\transpose}{^T}

\newcommand{\IGE}{IGE}
\newcommand{\ISE}{ISE}

% Bold that works both for letters and greek symbols
\renewcommand{\vec}[1]{\boldsymbol{\mathbf{#1}}}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}

% Numbering of supplementary figures as per http://bytesizebio.net/2013/03/11/adding-supplementary-tables-and-figures-in-latex/
\newcommand{\beginsupplement}{%
        \setcounter{table}{0}
        \renewcommand{\thetable}{S\arabic{table}}%
        \setcounter{figure}{0}
        \renewcommand{\thefigure}{S\arabic{figure}}%
     }

\journal{Journal Name}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

\title{Minimal Data Needed for Valid \& Accurate Image-Based fMRI Meta-Analysis}

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for the associated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for the associated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for the associated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%%
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}


%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{<author name>}
%% \address[label1]{<address>}
%% \address[label2]{<address>}

\author{Camille Maumet}
\author{Thomas Nichols}

\address{Oxford Big Data Institute, Li Ka Shing Centre for Health Information and Discovery, Nuffield Department of Population Health, University of Oxford, Oxford, UK}
\address{Statistics Department, University of Warwick, Coventry, UK.}

\begin{abstract}
%% Text of abstract
Meta-analysis provides a quantitative approach to summarise the rich functional Magnetic Resonance Imaging literature (fMRI). When image data is available for each study, a number of approaches have been proposed to perform such meta-analyses including combination of standardised statistics, just effect estimates or both effects estimates and their sampling variance. While the latter is the preferred approach in the statistical community, its properties are only guaranteed in large samples. Additionally, often only standardised estimates are shared, reducing the possible meta-analytic approaches. Finally, because the BOLD signal is non-quantitative care has to be taken in order to insure that effect estimates are expressed in the same units, especially when combining data from different software packages. Given the growing interest in data sharing in the neuroimaging community there is a need to identify what is the minimal data to be shared in order to allow for future image-based meta-analysis. In this paper, we compare the validity and the accuracy of nine meta-analytic approaches on simulated and real data. 

%% TODO review conclusion in terms of the new results
% In one-sample tests, combination of contrast estimates into a random-effects General Linear Model or non-parametric statistics provide a good approximation of the reference approach. If only standardised statistical estimates are shared, permutations of z-score is the preferred approach.
\end{abstract}

\begin{keyword}
Meta-analysis \sep Neuroimaging \sep Mixed-effects 
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}


%% main text
\section{Introduction}

A growing literature is focusing on the lack of statistical power in neuroimaging studies (see, e.g.~\cite{Button2013}), feeding the debate on the validity and reproducibility of published neuroimaging results. Meta-analysis, by providing inference based on the results of previously conducted studies, provides an essential method to increase power and hence confidence in neuroimaging.

A number of methods have been proposed for neuroimaging meta-analysis (see~\cite{Radua2012} for a review). As the results of neuroimaging studies are usually conveyed by providing a table of peak coordinate and statistics, most of these meta-analyses are restricted to combining coordinate-based information. Nevertheless the best practice method is an Image-Based Meta-Analysis (IBMA) that combines the effect estimates and standard errors from each study~\cite{Salimi-khorshidi2009}. 

In order for IBMA to be possible in neuroimaging, tools for sharing 3D volumes obtained as a result of a statistical analysis are needed. NeuroVault~\cite{Gorgolewski2015} is an example of one such plateform which facilitates sharing of neuroimaging results data but emphasis is mainly on statistical maps. There are three evident approaches to sharing summary data from each study $i$:
\begin{enumerate}
	\item the contrast estimates $\effect$ and contrast variance estimates $\vareffect$.
	\item the contrast estimates $\effect$.	
	\item the standardized statistic maps $\zeffect$.		
\end{enumerate}

Depending on how much data is shared, different strategies can be used to combine the available results into a meta-analysis. While the first option is the best practice, leading to statistically optimal estimates~\cite{Cummings2004}, it requires the contrasts to be expressed with in the same units and inference relies on asymptotic results (i.e under large sample sizes). In fMRI, units will depends on the field strength~\cite{Chen2016} as well as data, model and contrast vector scaling~\cite{Nichols2012units} and the number of samples included in a meta-analysis is usually small.

Given the growing interest in data sharing in the neuroimaging community, and the relative easiness of sharing and combining just (unitless) statistic maps, there is a need to identify what is the minimal data to be shared in order to allow for future IBMA.

Here we compare the use of IMBA using 9 meta-analytic approaches: 2 approaches use $\effect$'s and $\vareffect$'s, 2 $\effect$'s only and 5 $\zeffect$'s. We compare the validity and the accuracy of the nine meta-analytic approaches on simulated and real data including 21 studies of pain in control subjects.

Section~\ref{sec_meth} describes the meta-analytic estimates along with the experiments undertaken on simulated and real data to assert their validity. The results are described in section~\ref{sec_res}. Finally, we conclude in section~\ref{sec_ccl}.

\begin{figure}[t]
	\centering
% 	\includegraphics[width=\linewidth]{./MICCAI_version/Rplot_FPR_all.pdf}
	\caption{False positive rates of the meta-analytic estimators under the null hypothesis for $p<0.05$.}
	\label{fig_fpr_all}
\end{figure}

\section{Methods}\label{sec_meth}
\subsection{Theory}
For study $\studyidx=1,\ldots,\nStudies$ we have contrast estimate $\effect$, its contrast variance estimate $\vareffect$ (i.e. squared standard error), its equivalent Z-statistic map $Z_i$ and its sample size $n_i$.  

\paragraph{Combining contrast estimates and their standard error}

The gold standard approach is to fit contrast estimates and their standard error with a hierarchical general linear model (GLM)~\cite{Cummings2004}, creating a third-level (level ~1:~subject; level~2:~study; level~3:~meta-analysis). The general formulation for the study-level data is:

\begin{equation}
	\vec{\effectvector} = X \metaanalyticeffect + \epsilon
	\label{eq_meta_GLM}
\end{equation}
where $\metaanalyticeffect$ is the meta-analytic parameter to estimate, $\vec{\effectvector} = [\effect[1] \ldots \effect[\nStudies] ]\transpose$ is the vector of contrast estimates, $X$ is the $k\times p$ study-level matrix (typically just a column of ones for a one-sample test) and $\epsilon \sim \mathcal{N}(0,W)$ is the residual error term. 


% TODO: table FFX GLM should sum up to k x n

In the most general case of a random-effects (RFX) meta-analysis, we have $W = \mathrm{diag}( \varWithinCon[1] + \varBetween, \ldots ,\varWithinCon[\nStudies] + \varBetween )$ where $\varBetween$ denotes the between-study variance and $\varWithinCon$ denotes the contrast variance for study $i$. Eq.~\eqref{eq_meta_GLM} can be solved by weighted least squares giving:

\begin{eqnarray}
	\vec{\hat \metaanalyticeffect}  &=& (X\transpose W^{-1} X)^{-1} X\transpose W^{-1} \effectvector \\
	\Var(\vec{\hat \metaanalyticeffect})  &=& (X\transpose W^{-1} X)^{-1}
	\label{eq_WLS}
\end{eqnarray}


But in practice, the weight matrix $W$ is unknown and has to be estimated from the data. Given $\hat W$ a consistent estimate of $W$, the feasible generalized least squares (FGLS) estimator is computed as:
\begin{eqnarray}
	\vec{\hat \metaanalyticeffect}  &=& (X\transpose \hat W^{-1} X)^{-1} X\transpose \hat W^{-1} \effectvector \\
	\Var(\vec{\hat \metaanalyticeffect})  &=& (X\transpose \hat W^{-1} X)^{-1}
	\label{eq_FGLS}
\end{eqnarray}

Approximating $\varWithinCon$ by $\vareffect$ and given $\estvarBetween$ an estimate of $\varBetween$ we obtain the estimate detailed in Table~\ref{table:estimates_test1} for a one-sample test. Asymptotic theory shows that inference can be carried out by comparing the statistic to a Student distribution with $k-1$ degrees of freedom $+ADD_REF$ as depicted in  Table~\ref{table:stats_test1}. This reference approach will be referred to as \textbf{Mixed-effects (MFX) GLM}.


In a \textbf{fixed-effects (FFX) GLM}, i.e. assuming no or negligible between-study variance, $W = \mathrm{diag}( \varWithinCon[1], \ldots ,\varWithinCon[\nStudies])$. Approximating $\varWithinCon$ by $\vareffect$ we obtain the feasible generalied least squares estimate detailed in Table~\ref{table:estimates_test1} for a one-sample test. Asymptotic theory shows that inference can be carried out by comparing the statistic to a Student distribution with $(\sum_{\studyidx} n_\studyidx*\nStudies)-1$ degrees of freedom $+ADD_REF$ as depicted in  Table~\ref{table:stats_test1}. 

% Question: do we want FFX with fixed within study var?? > rather do RFX!?
% Under the asumption of constant study-level contrast variance (i.e.\ $\varWithinCon \simeq \sigma^2$), with the FFX model we have $W = \mathrm{diag}( \sigma^2, \ldots ,\sigma^2)$ and the system can be solved by Ordinary Least Squares leading. This approach will be referred to as \textbf{Homoscedastic FFX GLM}. TODO: is this paragraph true?? When the within-study variance is constant across studies, those (FFX) results are also true for small samples. -> we need to implement this one!!

% TODO: We need a second table (appendix?) for two-sample tests

\begin{table*}[t]
\begin{center}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{cccl}
				& $\hat \metaanalyticeffect$			& $\Var(\hat \metaanalyticeffect)$ &  Assumptions\\
\hline						
MFX GLM 		& $ \left( \sum \kappa_i \effect \right) / \left( \sum \kappa_i \right)$ with $\kappa_i = 1/(\estvarBetween + \vareffect)$ & $1/\sum \kappa_i$ & IGE.\\
RFX GLM 		& $ \sum \effect/\nStudies $ & $ \varCombined/\nStudies $  & IGE; $\varBetween+\varWithin = \varCombined\; \forall i$ \\
FFX GLM 		& $ \left( \sum \effect \times \varWithinConInv \right) / \left(\sum \varWithinConInv \right)$ & $1/(\sum \varWithinConInv)$ & IGE; $\varBetween=0$.\\
Contrast Perm.	& $ \sum \effect/\nStudies $ & Empirical & ISE.\\
Z MFX 		& $ \sum \zeffect/\nStudies $ & $ \varCombined/\nStudies $  & IGE; $1 + \varBetween/\varWithin$ cst.\\
Z Perm.	& $\left(  \sum_{i=1}^\nStudies \zeffect \right) / \sqrt{\nStudies}$ & Empirical & ISE.\\
\hline 

\end{tabular}
\end{center}
\caption{One-sample meta-analytic estimates, sampling variance and associated assumptions. Note: $\peffect = \Phi(-\zeffect)$}
\label{table:estimates_test1}
\end{table*}


\begin{table*}[t]
\begin{center}
\setlength{\tabcolsep}{3pt}
\begin{tabular}{ccccl}
				& Meta-analysic statistic			& Nominal H$_0$ distrib. & Inputs & Properties\\
\hline						
MFX GLM 		& $ \left( \sum \kappa_i \effect \right) / \sqrt{\sum_{i=1}^\nStudies \kappa_i}$ with $\kappa_i = 1/(\estvarBetween + \vareffect)$ & $\mathcal{T}_{\nStudies - 1}$ & $\effect, \vareffect$& Asymptotic.\\
RFX GLM 		& $  \left( \sum_{i=1}^\nStudies \frac{\effect}{\sqrt{\nStudies} } \right) / \widehat\varCombined  $ & $\mathcal{T}_{\nStudies - 1}$ & $\effect$ & Finite sample.\\
Ctrst Perm.	& $ \left( \sum_{i=1}^\nStudies \frac{\effect}{\sqrt{\nStudies}} \right) /\widehat\varCombined  $ & Empirical & $\effect$ & ??.\\
FFX GLM 		& $  \left(  \sum_{i=1}^{\nStudies}  \frac{\effect}{\vareffect} \right) / \sqrt{\sum_{i=1}^\nStudies 1/\vareffect } $ & $\mathcal{T}_{ (\sum_{i=1}^\nStudies n_i - 1) - 1}$ & $\effect, \vareffect$ 
& Asymptotic.\\
Fisher	& $ \displaystyle -2 \sum_{\studyidx} \ln \peffect $ & $\chi^2_{(2\nStudies)}$ & $\zeffect$ & ??.\\
Stouffer& $ \displaystyle \sqrt{\nStudies} \times \frac{1}{\nStudies} \sum_{\studyidx} \zeffect $ & $\mathcal{N}(0,1)$ & $\zeffect$& ??.\\
Weighted Z& $  \displaystyle \frac{1}{\sqrt{\sum_{\studyidx} n_\studyidx}} \sum_{\studyidx}  \sqrt{n_\studyidx} \zeffect  $ & $\mathcal{N}(0,1)$ & $\zeffect, \sampleSize$& ??.\\
Z MFX& $ \left(   \sum_{i=1}^\nStudies \zeffect \right)/ \sqrt{\nStudies} \hat \sigma$ & $\mathcal{T}_{\nStudies-1}$ & $\zeffect$& ??.\\
Z Perm.	& $\left(  \sum_{i=1}^\nStudies \zeffect \right) / \sqrt{\nStudies}$ & Empirical & $\zeffect$ & ??.\\
\hline 

\end{tabular}
\end{center}
\caption{Statistics for one-sample meta-analysis tests and their sampling distributions under the null hypothesis $H_0$. Empirical null distributions are determined using permutations with sign flipping. \IGE=Independent Gaussian Errors, \ISE=Independent Symmetric Errors. Note: $\peffect = \Phi(-\zeffect)$, $\widehat\varCombined$ is the unbiased sample variance.}
\label{table:stats_test1}
\end{table*}	

\paragraph{Combining contrast estimates}
If the $\vareffect$ are unavailable, the contrast estimates $\effect$ can be combined by assuming that the within-study contrast variance $\varWithinCon$ is constant ($\varWithinCon = \sigma^2 \;\; \forall i$) or negligible in comparison to the between-study variance ($\varWithinCon \ll \varBetween$). Then $W = \mathrm{diag}( \varCombined, \ldots, \varCombined )$ where $\varCombined$ is the combined within and between-subject variance, i.e.\ $\varCombined \simeq \varBetween$ or $\varCombined \simeq \varBetween + \varWithinCommon$ (note, however, in this setting we do not separately estimate $\varBetween$ or $\varWithinCommon$). Under these assumptions, Eq.~\eqref{eq_meta_GLM} can be solved by ordinary least squares giving:

\begin{eqnarray}
	\hat \metaanalyticeffect  &=& (X\transpose X)^{-1} X\transpose \effectvector \\
	\Var(\hat \metaanalyticeffect)  &=& (X\transpose X)^{-1} \varCombined
	\label{eq_OLS}
\end{eqnarray}

Given $\estvarCombined$ the unbiased sample variance, we obtain the statistics presented in Table~\ref{table:estimates_test1} for one sample tests. This approach will be referred to \textbf{RFX GLM} in the following. Inference can be carried out by comparing the RFX GLM statistic to a Student distribution with $\nStudies-1$ degrees of freedom, this result holds asymptotically as well as in small samples $+ADD_REF$. 

As an alternative to parametric approaches, non-parametric inference~\cite{Holmes1996,Nichols2002} can be performed by comparing the one-sample RFX GLM T-statistic to the distribution obtained with ``sign flipping'', i.e.\ randomly multiplying each study's data by 1 or -1, justified by an assumption of independent studies and symmetrically distributed random error. For two-sample tests, the non-parameteric distribution can be obtained by random permutation of the group labels. This approach will be referred to as \textbf{Contrast permutation}.

% TODO: We should be able to do something if we have the sample sizes by assuming constant within subject variance

\paragraph{Combining standardised statistics} 
When only test statistic images are available there are a several alternative approaches available. \textbf{Fisher}'s meta-analysis provide a statistic to combine the associated p-values~\cite{Fisher1932}. \textbf{Stouffer}'s approach combines directly the standardised statistic~\cite{Stouffer1949}. In \cite{Zaykin2011} following \cite{Liptak1958}, the author proposed a weighted method that weights each study's $\zeffect$ by the square root of its sample size [3,7]. This approach will be referred to as \textbf{Weighted Stouffer's}. All these meta-analytic statistics assumes no or negligible between-study variance and are only suited for one-sample tests. The corresponding statistics are presented in Table~\ref{table:stats_test1}.
As suggested in~\cite{Salimi-khorshidi2009}, to get a kind of MFX with Stouffer's approach, the standardised statistical estimates $\zeffect$ can be combined in an OLS analysis. The corresponding estimate, referred as \textbf{Z MFX} is also provided in~\ref{table:stats_test1}

Non-parametric inference~\cite{Holmes1996,Nichols2002} can also be obtained by sign flipping on the $\zeffect$'s. This approach will be referred to as \textbf{Z permutation}.

\paragraph{Approximations}  In practice, methods based on FGLS (MFX and FFX) have approximate parametric null distributions.  The nominal distributions of RFX and two-sample contrast permutations are under the (unrealistic) assumption of homogeneous standard errors over studies; even if all studies are `clean' and conducted at the same center, variation in sample size will induce differences in $\vareffect$'s. The fixed-effects methods (Fisher, Stouffer, wieghted Z and FFX GLM) assume homogeneity across studies, i.e. zero between-study variance. Finally, all contrast methods (MFX, RFX, Contrast permutation and FFX) require the contrasts to be expressed with in the same units.


% \begin{figure}[t]
% 	\centering
% 	\includegraphics[width=\linewidth]{./MICCAI_version/Rplot_valids.pdf}
% 	\caption{False positive rates of the RFX meta-analytic estimators under $H_0$ for $p<0.05$ as a function of the number of studies and the within-study variance.}
% 	\label{fig_fpr_valid}
% \end{figure}

\subsection{Experiments}

\subsubsection{Simulations}
We used Monte Carlo simulations to empirically investigate the validity of each estimator. We simulated a set of  contrast estimates $\effect$ and contrast variance estimates $\vareffect$ according to:
\begin{eqnarray}
	\effect &\sim& \mathcal{N}(0, \frac{\varWithin}{\sampleSize[]}+\varBetween) \\
	\vareffect &\sim& \frac{\varWithin}{\sampleSize[]}  \frac{\chi^2_{(\sampleSize[]-1)}}{\sampleSize[]-1} %
\end{eqnarray}
% TODO remove unclear alpha notation
where $\varWithin = \varWithin[] \alpha_i$ with $\varWithin[] \in \sampleSize[] \times [0.25, 0.5, 1, 2, 4]$ and $\alpha_i$ is either equal to 1 for all studies or is taken from $\alpha_i \in [1, 2, 4, 8, 16]$ to simulate varying within-study variances, $\varBetween \in [0, 1]$ is the between-study variance. Four different number of studies per meta-analysis were used: $\nStudies \in [5, 10, 25, 50]$. We set the number of subjects per studies $\sampleSize[]=20$ which is a common sample size in existing neuroimaging studies~\cite{Poldrack2017}. A total of 72 parameter sets (9 $\varWithin$ x 2 $\varBetween$ x 4 $\nStudies$) was therefore tested and a total of $1~026~000$ realisations was performed for each parameter set.

Three types of analyses were computed: a one-sample meta-analysis (testing significance on the mean effect in 1 group of \nStudies), a two-sample meta-analysis (testing significance in mean differences between two groups of $\nStudies$ each) and an unbalanced two-sample meta-analysis (testing significance in mean differences between two groups of 2*$\nStudies$/5 and 2*$\nStudies$*4/5 respectively).

We conducted simulations to evaluate the validity of each estimator in small samples and under violations of their assumptions, namely inhomogeneity of contrast variances $\vareffect$, presence of non-negligible between-study variance.

Furthermore, we studied the robustness of contrast-based methods to the presence of mismatched units across studies. To simulate units mismatch, each contrast estimates $\effect$ and contrast variance estimates $\vareffect$ was replaced by a rescaled version: $\effectunits = \effect a_i$ and $\vareffectunits = \vareffect a_i^2$. 2 types of unit mismatched were investigated: 
\begin{itemize}
	\item Mismatch in scaling of the contrast vectors: $a_i$ linearly sampled between $0.4$ and $1.6$ (mean is 1).
	\item Mismatch in data scaling from different sofware: for each group $a_i$=1 for $i <= n_{soft1}$ $a_i$=1 for $i > n_{soft1}$ with $n_{soft1} \in \{1/5, 1/2\}*n_g$ where $n_g$ is the number of studies in the group.
\end{itemize}


% TODO: table summarising the simulations + revisit number of settings stated in text above if needed
The full set of simulations is summarised is table~\ref{table:simu_settings}. Code is available at: \url{https://github.com/cmaumet/zmeta_buster}.


\subsubsection{Real data}
We then compared the nine meta-analytic estimators to the reference approach, MFX GLM, on a dataset of 21 studies of pain. 
Comparability of contrast estimates depends on equivalent scaling of the data, models, and contrast vectors. Data scaling was consistently performed by FSL, setting median brain intensity to 10,000; model were all created by FSL's Feat tool; and contrasts were constructed to preserve units, with sum of positive elements equal to 1, sum of negative elements equal to -1. 


% TODO: Anyone who knows the slightest bit about meta-analysis will know about Cochran's Q test and the I^2 test.  I think you've created some version of I^2 (maybe).  ANYWAY, it's good to mention these somewhere (intro) and say that that we propose an intuitive exploratory metric to assess heterogentiy that complents existing methods (Cochran's Q, I^2).

% See this ref: 

% Higgins, J. P. T., & Thompson, S. G. (2002). Quantifying heterogeneity in a meta-analysis. Statistics in Medicine, 21(11), 1539–58. doi:10.1002/sim.1186


To investigate the presence of between-study variation, we computed the ratio of the between-study variance (estimated using FSL's FLAME~\cite{Smith2001}) to the total variance (sum of between- and within-study variances), as suggested in~\cite{Chen2012}. Here we use the average (across study) within-study variance as an estimate of within-study variance in the denominator:
$\estvarBetween / (\estvarBetween + \sum_{i=1}^{\nStudies} \vareffect)$.
Using this metric, voxels with values close to 0 present negligible between-study variance and values close to 1 outline appreciable study heterogeneity and the importance of RFX~models.

Then for each estimator we compared the standardised meta-analytic statistic to the z-statistic obtained with the reference approach. Overestimation of z-statistic leads to overly optimistic detections while underestimation outline a reduced sensitivity of the approach. 

% \begin{figure}[t]
% 	\centering
% % 	\includegraphics[width=0.7\linewidth]{./MICCAI_version/Rplot_ratio_variances.pdf}
% 	\caption{Histogram of the between-study variance to the sum of the between-subject variance and the mean within-study variance.}
% 	\label{fig_realdata_variances}
% \end{figure}

\section{Results}\label{sec_res}

\subsection{Robustness to violation of model assumptions}

\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/small_samples/robustness.pdf}
	\caption{Deviation from theoretical P-values in one-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). P-values are displayed using a negative log$_{10}$ scale.}
	\label{fig:robustness}
\end{figure}

% TODO: lengend needs to be reworeked: in particular rework "factor(withinInfo)" 

% \begin{figure}[h]
% 	\centering
%  	\includegraphics[width=0.8\linewidth]{../zmeta/small_samples/test1_smallsample_robustness_subjects_p.pdf}
% 	\caption{Deviation from theoretical P-values in one-sample tests under ideal circunstances with respect to heterogeneity for each statistical approach ($\varBetween=0$ for FFX and $\varBetween=1$ for MFX) and $\sampleSize = 20, 100$ with matched (``nominal'') units.}
% 	\label{small_number_of_subjects_test1}
% \end{figure}

% TODO: need to add ref for figures: ggplot2 + grid..

Fig.~\ref{fig:robustness}A presents the one-sample simulation results in small samples, i.e. under small number of studies or small number of subjects. We focus here on methods fow which valitidy is only guaranteed in large samples: FFX and MFX, under ideal conditions otherwise (i.e. $\varBetween$=0 for FFX and $\varBetween$=1 for MFX). When the number of subjects is small, FFX is invalid for all within-study variances investigated, regardless of the number of studies included in the meta-analysis. On the other hand MFX GLM is conservative for small number of studies and constant within-study variance. Surprinsingly, while MFX GLM is valid for constant within-study variances it is invalid in the presence of large variations in the within-study variances, regardless of the number of subjects included in each study. 

In the nominal case, i.e. when the units are matched across studies and contrasts, RFX GLM and Contrast Permutation are valid, as expected. For small P-values, Contrast Permutation is conservative as expected due to the discrete nature of its distribution. In the presence of a high within-study variance, MFX GLM also appears to be conservative. RFX GLM displays the best behaviour with a pattern that is within the 95\% confidence interval of the theoretical Z for all within-study variance studied and only slightly conservative when the within-study variances are varying across studies.

For small number of studies, permutation methods (including Contrast Permutation and Z permutation) are conservative as expected due to the discrete nature of their distribution (cf. supplementary figure TODO).

Other approaches (TODO) have a nominal behaviour under small sample sizes as expected according to theory. Only Stouffers MFX presents some invalidity, which can be explained by the fact that this is an had hoc not recommended statistic (cf. supplementary figure TODO).

Fig.~\ref{fig:robustness}B presents the one-sample simulation results under heteroscedasticity ($\varWithin$ non constant over studies). We focus here on methods fow which valitidy is only guaranteed under homoscedasticity: RFX and Contrast permutation, with a sample of $25$ studies under ideal conditions otherwise (i.e. $\varBetween$=1). RFX and Perm E. are robust to heteroscedasticity for all settings studied. RFX is closer to nominal. For small P-values, Contrast Permutation is conservative as expected due to the discrete nature of its distribution.

Fig.~\ref{fig:robustness}C presents the one-sample simulation results under heterogeneity ($\varBetween>0$). We focus here on methods fow which valitidy is only guaranteed under homogeneity: Fisher, Stouffer, Weighted Z and Fixed-effects GLM, with a sample of $25$ studies. All fixed-effects methods are invalid under heterogeneity.

Similar behaviours are observed for two-sample tests (cf. Supplementary Fig.~\ref{fig:robustness_test2} and Fig.~\ref{fig:robustness_test3}).

\subsection{Robustness to units mismatch}

\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/units_mismatch/units.pdf}
	\caption{Deviation from theoretical P-values in one-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). Deviation from theoretical Z in two-sample tests with unit mismatch, under ideal circunstances for each statistical approach ($\varBetween=1$ and $\nStudies = 5, 25, 50$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{fig:units}
\end{figure}

Fig.~\ref{fig:units} presents the simulation results under unit mismatches for one-sample tests. 

When different scaling algorithm are used (Fig.~\ref{fig:units}, 2nd and 3rd columns), e.g. with different neuroimaging software packages (provided that differences in scaling targets have been accounted for), Contrast Permutation has a behaviour that is close to nominal. RFX GLM is valid conservative. MFX GLM is robust to the presence of robust mimatches when the studies are homoscedastic. In the presence of strong heteroscedasticity, MFX GLM remains invalid as when the units are matched due to small sample size (cf. previous paragraph). In the presence of slight heteroscedasticity, unit mismatchs can cause invalidity. 

When the contrast are scaled differently (Fig.~\ref{fig:units}, 4th column), we observe a very similar pattern than for different scaling algorithm.

Similar behaviours are observed for two-sample tests (cf. Supplementary Fig.~\ref{fig:units_test2} and Fig.~\ref{fig:units_test3}).


\subsection{Small sample properties}

\begin{figure}[h]
	\centering
 	\includegraphics[width=0.8\linewidth]{./figures/samplesizes_test1.pdf}
	\caption{}
	\label{samplesizes_test1}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[width=0.8\linewidth]{./figures/samplesizes_test2.pdf}
	\caption{}
	\label{samplesizes_test2}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[width=0.8\linewidth]{./figures/samplesizes_test3.pdf}
	\caption{}
	\label{samplesizes_test3}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[width=0.8\linewidth]{./figures/rfx_assump.pdf}
	\caption{}
	\label{rfx_assump}
\end{figure}


\subsubsection{Group meta-analysis}

\begin{figure}[t]
	\centering
 	\includegraphics[width=\linewidth]{./figures/test1_btw1.png}
	\caption{Deviation from theoretical Z in one-sample tests with $\varBetween=1$ and $\nStudies = 5, 25, 50$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{test1_k25_btw1}
\end{figure}

Fig.~\ref{test1_k25_btw1} presents the simulation results for a one-sample test with $\varBetween=1$ and a sample size $\nStudies = 5, 25, 50$. For the nominal case, i.e. when the units are matched across studies and contrasts, MFX GLM, RFX GLM and Contrast Permutation are all valid, as expected. For small sample sizes ($\nStudies = 5$), MFX GLM and contrast permutation are both very conservative. For large values of Z, Contrast Estimation is conservative as expected due to the discrete nature of its distribution. More suprinsing, in the presence of a high within-study variance, MFX GLM also appears to be conservative. RFX GLM displays the best behaviour with a pattern that is always within the 95\% confidence interval of the theoretical Z.

% In the extreme case of different scaling target, i.e. when data where scaled to a different mean (100 versus 10 000), Contrast Permutation displays a pattern that is very close to its nominal behaviour, namely it is valid but conservative for large Z. GLM RFX is valid for Z values that are greater than 1.5 (i.e. the area we are interested in in terms of detections) but very conservative, especially when the number of samples from each scaling factor are not equal. This behaviour is expected as the estimated between-study variance is inflated by the difference in scaling target. MFX GLM is invalid for small within-study variances and conservative for large within-subject variances.


\subsubsection{Balanced between-group meta-analysis}

Fig.~TODO presents the simulation results for a two-sample meta-analyses with $\varBetween=1$ and a sample size $\nStudies = 25$. For the nominal case, GLM RFX, GLM RFX and contrast estimation provide valid estimates. Contrast Permutation is conservative for large Z values. Both RFX GLM and MFX GLM display the best behaviour with a pattern that is within the 95\% confidence interval of the theoretical Z.

In the extreme case of different scaling target, contrast permutation is always valid with a pattern very similar than its nominal behaviour. GLM RFX is valid for Z values greater than 1.5, which is the area of interest in detections, but display a strong conservativness, more pronounced than the Contarst Permutation. GLM MFX is slighlty invalid for all within-study variances except the largest one when 20\% of the studies come from the second software.

\begin{figure}[t]
	\centering
 	\includegraphics[width=0.99\linewidth]{./figures/test2_btw1.png}
	\caption{Deviation from theoretical Z in balanced two-sample tests with $\varBetween=1$ and $\nStudies = 25$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{test2_btw1}
\end{figure}

\subsubsection{Unbalanced between-group meta-analysis}

\begin{figure}[t]
	\centering
 	\includegraphics[width=0.99\linewidth]{./figures/test3_btw1.png}
	\caption{Deviation from theoretical Z in unbalanced two-sample tests with $\varBetween=1$ and $\nStudies = 25$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{test3_btw1}
\end{figure}

Fig.~TODO presents the simulation results for unbalanced two-sample meta-analyses with $\varBetween=1$ and a sample size $\nStudies = 25$. For the nominal case, MFX GLM, GLM RFX and contrast permutation provide valide estimate. As expected due to the discrete nature of its ampling distribution, contrast permutation is conservative for large Z value. GLM RFX is conservative. RFX GLM is closest to the theoretical behaviour with Z-values that are always within the 95\% confidence interval.

In the extreme case of different scaling target, MFX GLM is always valid but slightly conservative. RFX GLM is valid for Z values greater than 1.5 (area of interest in detections) but conservative. Similarly contrast permutation is invalid for Z smaller than 1.5 and conservative otherwise. This can be explained by the violation of the exchangeability condition.

When different scaling algorithm are used, (same paragraph as for one-sample test)

When the contrast are scaled differently, we observe a very similar pattern than for different scaling algorithm with higher varaince of the estimates.


\subsection{Simulations}
Fig.~\ref{fig_fpr_all} displays the false positive rate at $p<0.05$ obtained for the nine estimators over all set of parameters in the absence and presence of between-study variation. As expected, the fixed-effects meta-analytic summary statistics, i.e.\ Fisher's, Stouffer's and weighted Stouffer's estimates, are liberal in the presence of study heterogeneity. The original Fisher's approach is the most invalid. More surprising, FFX GLM is also invalid with homogeneous studies. The explanation is over-estimation of degrees-of-freedom (DF); while DF is computed as $(\sum n-1)-1$, under heteroscasdicity (from $\sigma_i$ or $\sampleSize$) it will be much lower~\cite{Satterthwaite}. Z MFX and GLM RFX provide valid estimates, and the permutation estimates are valid but tend to be conservative with greater variation in false positive rates.

The impact of the number of studies involved in the meta-analysis and of the size of the within-study variance are investigated in Fig.~TODO. Permutation inference is valid but conservative when 5 studies are used; this is because there are only $2^5=32$ possible permutations and thus $1/32=0.03125$ is largest attainable valid P-value. All approaches perform equally as soon as 10 or more studies are included in the meta-analysis. 


\subsection{Real data}



% The histogram of the ratio of between-subject variance to total variance is displayed in Fig.~\ref{fig_realdata_variances}. From this graph it is clear that for most of the voxels the estimated between-study variance is greater than the within-study variance. We can therefore suppose the presence of study heterogeneity (non negligible between-study variance) in this collection of studies.

\begin{figure}[t]
	\centering
% 	\includegraphics[width=0.8\linewidth]{./MICCAI_version/Rplot_realdata_ffx.pdf}
% 	\includegraphics[width=0.8\linewidth]{./MICCAI_version/Rplot_realdata_rfx.pdf}
	\caption{Difference between the z-score estimated from each meta-analytic approach and the reference z-score from MFX GLM as a function of reference z-score.}
	\label{fig_realdata}
\end{figure}


Fig.~\ref{fig_realdata} plots the difference between the z-score estimated by each meta-analytic approach against the reference z-score computed with MFX GLM. All FFX statistics provide overly optimistic z-estimate suggesting, again, that study heterogeneity is present in the studied dataset.
Among the RFX meta-analytic approaches, GLM RFX and contrast permutations provide z-scores estimate that are equal or smaller than the reference. Z permutation provides slightly larger z-scores between 1 and 3 (reference p-values between 0.16 and 0.0013) but is mostly in agreement with the reference z-scores. On the other hand, Z MFX is more liberal than the reference for z-score ranging from 3 to 5 (reference p-values between 0.0013 and 2.9e-07) and more stringent for z-scores smaller than 5.

% Fig. 1 shows the Bland-Altman plots comparing Z-scores from the Stouffer's and weighted-Z methods each compared with the ground truth Z-scores. Overall, both approaches present the same pattern of overestimation of the Z-scores. The weighted-Z approach provides a somewhat more condensed pattern suggesting a closer match to the ground truth.
% The dice similarity score for uncorrected p-values of 0.001, 0.01 and 0.05 were 0.84, 0.87 and 0.89 respectively for Stouffer's method and 0.86, 0.88 and 0.90 for the weighted Z-score, showing again slightly better results for the weighted-Z approach. These scores are notably higher (dice similarity scores range from 0 to 1) than the scores obtained with coordinate-based meta-analyses (around 0.5, [5]).
% Finally the ROC curves displayed in figure 2 for a ground truth obtained with an FDR corrected threshold p<0.05 demonstrate again a slight advantage of weighted-Z FFX over Stouffer's FFX.

% Dice among valids
% \begin{enumerate}
% \item StouffersMFX: 0.9454
% \item PermutZ: 0.9450
% \item GLMRFX: 0.8994
% \item PermutCon: 0.8991
% \end{enumerate}

% \begin{enumerate}
% \item WeightedZ: 0.9244
% \item Stouffers: 0.9184
% \item GLMFFX: 0.8972
% \item fishers: 0.8382
% \end{enumerate}

% AUC between 0 and 0.1
% among valids
% \begin{enumerate}
% \item StouffersMFX: 0.8924
% \item PermutZ: 0.8919
% \item GLMRFX: 0.7809
% \item PermutCon: 0.7815
% \end{enumerate}

% \begin{enumerate}
% \item  WeightedZ: 0.8293
% \item  Stouffers: 0.8619
% \item  fishers: 0.6329
% \item  GLMFFX: 0.6111
% \end{enumerate}

\section{Discussions}\label{sec:discussion}    
TODO: different scanners effect on units, event-related designs, analytical variability (maybe intro??)

\section{Conclusion}\label{sec_ccl}
We have compared nine meta-analytic approaches in the context of one-sample test. Through simulations, we found the expected invalidity of standard FFX approaches in the presence of study heterogeneity, but also of FFX GLM even with no between-study variation. In a real dataset of 21 studies of pain, there was evidence for substantial between-study variation that supports the use of RFX meta-analytic statistics. When only contrast estimates are available, RFX GLM was valid. This is in line with previous results on within-group one-sample t-tests studies~\cite{Mumford2009}. When only standardised estimates are available, permutation is the preferred option as the one providing the most faithful results. Further investigations are needed in order to assess the behaviour of these estimators in other configurations, including meta-analyses focusing on between-study differences.


\section{Acknowledgements}
We gratefully acknowledge the use of the pain dataset from the Tracey pain group, FMRIB, Oxford. The majority of this work was conducted while TEN and CM were at the University of Warwick.

%
% ---- Bibliography ----
\bibliographystyle{plain}
\bibliography{ibma}

\beginsupplement


\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/small_samples/robustness_test2.pdf}
	\caption{Deviation from theoretical P-values in two-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). P-values are displayed using a negative log$_{10}$ scale.}
	\label{fig:robustness_test2}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/small_samples/robustness_test3.pdf}
	\caption{Deviation from theoretical P-values in unbalanced two-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). P-values are displayed using a negative log$_{10}$ scale.}
	\label{fig:robustness_test3}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/units_mismatch/units_test2.pdf}
	\caption{Deviation from theoretical P-values in one-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). Deviation from theoretical Z in two-sample tests with unit mismatch, under ideal circunstances for each statistical approach ($\varBetween=1$ and $\nStudies = 5, 25, 50$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{fig:units_test2}
\end{figure}

\begin{figure}[h]
	\centering
 	\includegraphics[trim={0 0 0 0
 	},clip,width=0.8\linewidth]{../zmeta/units_mismatch/units_test3.pdf}
	\caption{Deviation from theoretical P-values in one-sample tests under violations of the underlying model assumptions: small sample sizes~(A), heteroscedasticity~(B) and heterogeneity~(C). Deviation from theoretical Z in two-sample tests with unit mismatch, under ideal circunstances for each statistical approach ($\varBetween=1$ and $\nStudies = 5, 25, 50$ with matched (``nominal'') or mismatched (``different scaling target", ``different scaling algorithm", ``different contrast vector scaling") units.}
	\label{fig:units_test3}
\end{figure}

% %
% \begin{thebibliography}{5}
% %
% \bibitem {clar:eke}
% Clarke, F., Ekeland, I.:
% Nonlinear oscillations and
% boundary-value problems for Hamiltonian systems.
% Arch. Rat. Mech. Anal. 78, 315--333 (1982)

% \bibitem {clar:eke:2}
% Clarke, F., Ekeland, I.:
% Solutions p\'{e}riodiques, du
% p\'{e}riode donn\'{e}e, des \'{e}quations hamiltoniennes.
% Note CRAS Paris 287, 1013--1015 (1978)

% \bibitem {mich:tar}
% Michalek, R., Tarantello, G.:
% Subharmonic solutions with prescribed minimal
% period for nonautonomous Hamiltonian systems.
% J. Diff. Eq. 72, 28--55 (1988)

% \bibitem {tar}
% Tarantello, G.:
% Subharmonic solutions for Hamiltonian
% systems via a $\bbbz_{p}$ pseudoindex theory.
% Annali di Matematica Pura (to appear)

% \bibitem {rab}
% Rabinowitz, P.:
% On subharmonic solutions of a Hamiltonian system.
% Comm. Pure Appl. Math. 33, 609--633 (1980)

% \end{thebibliography}


\end{document}

%%
%% End of file `elsarticle-template-1-num.tex'.